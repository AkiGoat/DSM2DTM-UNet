{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7884ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'pytorch-unet' already exists and is not an empty directory.\n",
      "/Users/hyde-mbp/Projects/Grad/pytorch-unet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"pytorch_unet.py\"):\n",
    "  if not os.path.exists(\"pytorch_unet\"):\n",
    "    !git clone https://github.com/usuyama/pytorch-unet.git\n",
    "\n",
    "  %cd pytorch-unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24c0596c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE                           pytorch_fcn.ipynb\r\n",
      "README.md                         pytorch_resnet18_unet.ipynb\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                       pytorch_unet.ipynb\r\n",
      "helper.py                         pytorch_unet.py\r\n",
      "\u001b[34mimages\u001b[m\u001b[m                            pytorch_unet_resnet18_colab.ipynb\r\n",
      "loss.py                           simulation.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c5bd8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce99673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Volumes/SamDick/Grad Project/Data/U_Net/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd27127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_images shape and range (136, 9, 9, 1) 0.14787010351816812 34.65899319118924\n",
      "target_masks shape and range (136, 2, 9, 9) False True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import helper\n",
    "import simulation\n",
    "\n",
    "# Generate some random images\n",
    "# input_images, target_masks = simulation.generate_random_data(9, 9, count=2)\n",
    "input_images = np.load(file_path+'DSMs.npy')\n",
    "target_masks = np.load(file_path+'Masks.npy')\n",
    "\n",
    "print(\"input_images shape and range\", input_images.shape, input_images.min(), input_images.max())\n",
    "print(\"target_masks shape and range\", target_masks.shape, target_masks.min(), target_masks.max())\n",
    "\n",
    "# Change channel-order and make 3 channels for matplot\n",
    "input_images_rgb = [x.astype(np.uint8) for x in input_images]\n",
    "\n",
    "# Map each channel (i.e. class) to each color\n",
    "target_masks_rgb = [helper.masks_to_colorimg(x) for x in target_masks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac1c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "input_images_rgb_ = []\n",
    "target_masks_rgb_ = []\n",
    "for i in random.sample(range(len(input_images_rgb)), 3):\n",
    "    input_images_rgb_.append(input_images_rgb[i])\n",
    "    target_masks_rgb_.append(target_masks_rgb[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b9d02de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "helper.plot_side_by_side([input_images_rgb_, target_masks_rgb_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc3616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, size, transform=None):\n",
    "#     self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)\n",
    "        input_images = np.load(file_path+'DSMs.npy')[:size]\n",
    "        target_masks = np.load(file_path+'Masks.npy')[:size]\n",
    "        self.input_images = input_images\n",
    "        self.target_masks = target_masks\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, size, transform=None):\n",
    "#     self.input_images, self.target_masks = simulation.generate_random_data(192, 192, count=count)\n",
    "        input_images = np.load(file_path+'DSMs.npy')[-size:]\n",
    "        target_masks = np.load(file_path+'Masks.npy')[-size:]\n",
    "        self.input_images = input_images\n",
    "        self.target_masks = target_masks\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.input_images[idx]\n",
    "        mask = self.target_masks[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return [image, mask]\n",
    "\n",
    "# use the same transformations for train/val in this example\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # imagenet\n",
    "])\n",
    "\n",
    "# train_set = SimDataset(2000, transform = trans)\n",
    "# val_set = SimDataset(200, transform = trans)\n",
    "\n",
    "train_set = TrainDataset(100, transform = trans)\n",
    "test_set = TestDataset(25, transform = trans)\n",
    "\n",
    "image_datasets = {\n",
    "  'train': train_set, 'test': test_set\n",
    "}\n",
    "\n",
    "batch_size = 5\n",
    "\n",
    "dataloaders = {\n",
    "  'train': DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "  'test': DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86c99658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 9, 9]) torch.Size([5, 2, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "print(inputs.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68008d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 9, 9]) torch.Size([5, 2, 9, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbe393869a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANPElEQVR4nO3dbWyd9XnH8e8Vx47z2ITysJJEhbY0K6tUwkJKiYQ2aAusiEpTX8DUVmsnZS9GG6ZqLd2bbtq7bULtC9YpCrBNUGhHYUIdgyK1VYs2AnnaICSoaVaC80gVmoCTxrF97YUPyKV5uM/x+fvE/30/UoTtc3LxM/jn+z7Ht68TmYmkeszqdQBJ3WWppcpYaqkyllqqjKWWKjO7xND+gfk5OLikxGgAZh07UWw2wPiCOUXnA8SRY0Xn56J5ReePvCOKzo+xouMB6Cv7ZcR4X7nZJ48eZvT48Cn/JxQp9eDgElatvr3EaADmbN1dbDbAsWveV3Q+wJx/f67o/JE1VxWdv+eGgl+xwMCR8ieRC14u++PckUXlvvHt+tZdp73N02+pMpZaqoyllipjqaXKWGqpMpZaqoyllirTqNQRcWNEvBQRuyLiztKhJHXurKWOiD7gbuAm4HLgtoi4vHQwSZ1pcqReDezKzN2ZOQI8BHyybCxJnWpS6qXAK5PeH2p97NdExNqI2BQRm06eHO5WPkltalLqU13A+hsXzWbm+sxclZmr+vvnTz2ZpI40KfUQsHzS+8uAfWXiSJqqJqV+DrgsIi6NiAHgVuCxsrEkdeqsv3qZmaMRcTvwJNAH3JuZ24snk9SRRr9PnZmPA48XziKpC7yiTKqMpZYqY6mlylhqqTKWWqqMpZYqU2RF8KxjJ4qu8c2lFxWbDTB/+8Gi8wH2fvGaovOXPjZUdP6Kr4wWnf/4ivI/Qf27w+8tOn/Dv3282Ow8Q3M9UkuVsdRSZSy1VBlLLVXGUkuVsdRSZSy1VBlLLVWmyYrgeyPiUES8MB2BJE1NkyP1PwE3Fs4hqUvOWurM/DFweBqySOoCH1NLlenaL3RExFpgLcDgrAXdGiupTV07Uk9e5j8Qg90aK6lNnn5LlWnyI60Hgf8CVkTEUET8SflYkjrVZJn/bdMRRFJ3ePotVcZSS5Wx1FJlLLVUGUstVcZSS5Upsvd75J2D7P2jD5QYDcC77n622GyAA5+/quh8gIsf/GnR+Ydufl/R+Yv+ZqTo/D/8q48VnQ8wK7Lo/IuuOlBs9v75J097m0dqqTKWWqqMpZYqY6mlylhqqTKWWqqMpZYqY6mlylhqqTJNNp8sj4gfRsSOiNgeEeumI5ikzjS5THQU+FJmbomIhcDmiHgqM18snE1SB5os89+fmVtab78O7ACWlg4mqTNtPaaOiEuAlcDGU9y2NiI2RcSmsePDXYonqV2NSx0RC4DvAndk5tG33z5573ff3PndzCipDY1KHRH9TBT6gcx8pGwkSVPR5NnvAO4BdmTmXeUjSZqKJkfqNcBngOsiYlvrzx8UziWpQ02W+T8NxDRkkdQFXlEmVcZSS5Wx1FJlLLVUGUstVcZSS5Upssx/4LUTLPvO7hKjAcgV7y02G+CC+zYXnQ8wfMMVRecveelY0fnDSweLzt//5GVF5wP8w+f/sej8DQevLTZ7R9/YaW/zSC1VxlJLlbHUUmUstVQZSy1VxlJLlbHUUmUstVSZJptPBiPi2Yj479be77+ejmCSOtPkirITwHWZ+UZrV9nTEfEfmflM4WySOtBk80kCb7Te7W/9yZKhJHWu6TbRvojYBhwCnsrMM+79Hhk/3uWYkppqVOrMHMvMK4BlwOqI+OAp7vPW3u+BWXO7HFNSU209+52ZvwR+BNxYIoykqWvy7PcFEbG49fZc4KPAzsK5JHWoybPf7wL+OSL6mPgm8J3M/F7ZWJI61eTZ7/9h4kXxJM0AXlEmVcZSS5Wx1FJlLLVUGUstVcZSS5Upsve7tCOXLy46f9HPyn+vm//Tw0XnH/y9C4rOn3Ok7O/0XPove4rOB/jKnj8tOv/D6zYVm90X46e9zSO1VBlLLVXGUkuVsdRSZSy1VBlLLVXGUkuVsdRSZRqXurV8cGtEuCBBOoe1c6ReB+woFURSdzRdEbwM+ASwoWwcSVPV9Ej9deDLwGkvOHXvt3RuaLJN9GbgUGZuPtP93PstnRuaHKnXALdExM+Bh4DrIuL+oqkkdeyspc7Mr2bmssy8BLgV+EFmfrp4Mkkd8efUUmXaWpKQmT9i4mV3JJ2jPFJLlbHUUmUstVQZSy1VxlJLlbHUUmWK7P0enzfA8MrlJUYDMHh4tNhsgPEr3l90PsB4f1/R+eevf6bo/JjdX3Q+F19Udj5w/k/2Fp3/7PjvFps9fPAnp73NI7VUGUstVcZSS5Wx1FJlLLVUGUstVcZSS5Wx1FJlGl180lpl9DowBoxm5qqSoSR1rp0ryn4/M39RLImkrvD0W6pM01In8P2I2BwRa091h8l7v0+ODHcvoaS2ND39XpOZ+yLiQuCpiNiZmT+efIfMXA+sB1i4eFl2OaekhhodqTNzX+ufh4BHgdUlQ0nqXJNX6JgfEQvffBv4OPBC6WCSOtPk9Psi4NGIePP+38rMJ4qmktSxs5Y6M3cDH5qGLJK6wB9pSZWx1FJlLLVUGUstVcZSS5Wx1FJliuz9zoDxgSgxGoD+o2PFZgOcOG9O0fkAY4Nlv5+e+OzVReePDRYdz8g7yn39vPXvWFT2auZ5+8p9DnmGtfEeqaXKWGqpMpZaqoyllipjqaXKWGqpMpZaqoyllirTqNQRsTgiHo6InRGxIyI+UjqYpM40vaLsG8ATmfmpiBgA5hXMJGkKzlrqiFgEXAv8MUBmjgAjZWNJ6lST0+/3AK8C90XE1ojY0FpA+Gsm7/0ePeHeb6lXmpR6NnAl8M3MXAkMA3e+/U6ZuT4zV2XmqtlzfqPzkqZJk1IPAUOZubH1/sNMlFzSOeispc7MA8ArEbGi9aHrgReLppLUsabPfn8BeKD1zPdu4HPlIkmaikalzsxtgK9JLc0AXlEmVcZSS5Wx1FJlLLVUGUstVcZSS5Wx1FJliizzv3DZa9z+t98uMRqAw6MLis0GuH/Ph4vOB9i/88Ki83/rP8suqu8/XnQ8vzqv/DL/hS+Xnf/a74wXm32mF1PwSC1VxlJLlbHUUmUstVQZSy1VxlJLlbHUUmXOWuqIWBER2yb9ORoRd0xDNkkdOOvFJ5n5EnAFQET0AXuBR8vGktSpdk+/rwd+lpmFr8WR1Kl2S30r8GCJIJK6o3GpW0sHbwH+9TS3v7XM//XDo93KJ6lN7RypbwK2ZObBU904eZn/wvOK/J6IpAbaKfVteOotnfOavpTtPOBjwCNl40iaqqZ7v48B7yycRVIXeEWZVBlLLVXGUkuVsdRSZSy1VBlLLVXGUkuVKXI95xtjgzx99P0lRgNww+Lni80G+Oy7nyk6H+DY8oGi8y+7+UDR+X+x7VNF54+MlL/UOLfPKzq//0i53eUxdvrbPFJLlbHUUmUstVQZSy1VxlJLlbHUUmUstVQZSy1Vpunmkz+PiO0R8UJEPBgRZ3jJa0m91OQVOpYCXwRWZeYHgT4mVgVLOgc1Pf2eDcyNiNnAPGBfuUiSpuKspc7MvcDfA3uA/cCRzPz+2+83ee/38dd+1f2kkhppcvq9BPgkcClwMTA/Ij799vtN3vs9d4kPuaVeaXL6/VHgfzPz1cw8ycSa4GvKxpLUqSal3gNcHRHzIiKYeJG8HWVjSepUk8fUG4GHgS3A862/s75wLkkdarrM/2vA1wpnkdQFXlEmVcZSS5Wx1FJlLLVUGUstVcZSS5WJzOz+0IhXgZfb+CvnA7/oepDpY/7em+mfQ7v5352ZF5zqhiKlbldEbMrMVb3O0Snz995M/xy6md/Tb6kyllqqzLlS6pl+Lbn5e2+mfw5dy39OPKaW1D3nypFaUpdYaqkyPS11RNwYES9FxK6IuLOXWToREcsj4ocRsaO1QnldrzN1IiL6ImJrRHyv11naFRGLI+LhiNjZ+v/wkV5nakeJ9ds9K3VE9AF3AzcBlwO3RcTlvcrToVHgS5n5AeBq4M9m4OcAsI6Zu83mG8ATmfnbwIeYQZ9HqfXbvTxSrwZ2ZebuzBwBHmJiweGMkZn7M3NL6+3XmfiCWtrbVO2JiGXAJ4ANvc7SrohYBFwL3AOQmSOZ+cuehmpf19dv97LUS4FXJr0/xAwrxGQRcQmwEtjY4yjt+jrwZWC8xzk68R7gVeC+1sOHDRExv9ehmmq6frtdvSx1nOJjM/LnaxGxAPgucEdmHu11nqYi4mbgUGZu7nWWDs0GrgS+mZkrgWFgxjw303T9drt6WeohYPmk95cxA1/5IyL6mSj0A5n5SK/ztGkNcEtE/JyJhz/XRcT9vY3UliFgqLUcEyYWZF7ZwzztKrJ+u5elfg64LCIujYgBJp4geKyHedrWWpl8D7AjM+/qdZ52ZeZXM3NZZl7CxH//H2TmlI8U0yUzDwCvRMSK1oeuB17sYaR2FVm/3WibaAmZORoRtwNPMvGs372Zub1XeTq0BvgM8HxEbGt97C8z8/HeRfp/5wvAA60Dw27gcz3O01hmboyIN9dvjwJb6cLlol4mKlXGK8qkylhqqTKWWqqMpZYqY6mlylhqqTKWWqrM/wEKNE9EVg76igAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchvision.utils\n",
    "\n",
    "def reverse_transform(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     mean = np.array([0.485, 0.456, 0.406])\n",
    "#     std = np.array([0.229, 0.224, 0.225])\n",
    "#     inp = std * inp + mean\n",
    "#     print(inp.shape)\n",
    "#     inp = np.clip(inp, 0, 1)\n",
    "#     inp = (inp * 255).astype(np.uint8)\n",
    "\n",
    "    return inp\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, masks = next(iter(dataloaders['train']))\n",
    "\n",
    "print(inputs.shape, masks.shape)\n",
    "\n",
    "plt.imshow(reverse_transform(inputs[4]))\n",
    "# reverse_transform(inputs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9052515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.base_layers = list(self.base_model.children())\n",
    "\n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n",
    "#         self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "#         self.layer3_1x1 = convrelu(256, 256, 1, 0)\n",
    "#         self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "#         self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "#         self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "#         self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 128, 128, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 128, 128, 3, 1)\n",
    "\n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "\n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        \n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = self.upsample(layer2)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "#         layer3 = self.layer3(layer2)\n",
    "#         layer4 = self.layer4(layer3)\n",
    "\n",
    "#         layer4 = self.layer4_1x1(layer4)\n",
    "#         x = self.upsample(layer4)\n",
    "#         layer3 = self.layer3_1x1(layer3)\n",
    "#         x = torch.cat([x, layer3], dim=1)\n",
    "#         x = self.conv_up3(x)\n",
    "\n",
    "#         x = self.upsample(x)\n",
    "#         layer2 = self.layer2_1x1(layer2)\n",
    "#         x = torch.cat([x, layer2], dim=1)\n",
    "#         x = self.conv_up2(x)\n",
    "\n",
    "#         x = self.upsample(x)\n",
    "#         layer1 = self.layer1_1x1(layer1)\n",
    "#         x = torch.cat([x, layer1], dim=1)\n",
    "#         x = self.conv_up1(x)\n",
    "\n",
    "#         x = self.upsample(x)\n",
    "#         layer0 = self.layer0_1x1(layer0)\n",
    "#         x = torch.cat([x, layer0], dim=1)\n",
    "#         x = self.conv_up0(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)\n",
    "\n",
    "        out = self.conv_last(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "605db1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_unet\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print('device', device)\n",
    "\n",
    "model = ResNetUNet(2)\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0b3dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetUNet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer0_1x1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1_1x1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2_1x1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3_1x1): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer4_1x1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv_up3): Sequential(\n",
       "    (0): Conv2d(384, 256, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up2): Sequential(\n",
       "    (0): Conv2d(320, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up1): Sequential(\n",
       "    (0): Conv2d(160, 128, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up0): Sequential(\n",
       "    (0): Conv2d(96, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size0): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size1): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size2): Sequential(\n",
       "    (0): Conv2d(96, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84d13db7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNetUNet' object has no attribute 'conv_original_size0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m----> 2\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mResNetUNet.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 44\u001b[0m     x_original \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_original_size0\u001b[49m(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     45\u001b[0m     x_original \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_original_size1(x_original)\n\u001b[1;32m     47\u001b[0m     layer0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer0(\u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1261\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1261\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ResNetUNet' object has no attribute 'conv_original_size0'"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 8, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
