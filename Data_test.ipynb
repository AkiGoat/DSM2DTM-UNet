{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6836fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb242b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77300051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1036.771728515625\n",
      "199 713.550537109375\n",
      "299 492.5128479003906\n",
      "399 341.17999267578125\n",
      "499 237.45126342773438\n",
      "599 166.2705841064453\n",
      "699 117.36976623535156\n",
      "799 83.73703002929688\n",
      "899 60.579498291015625\n",
      "999 44.6171760559082\n",
      "1099 33.60249710083008\n",
      "1199 25.993764877319336\n",
      "1299 20.73233413696289\n",
      "1399 17.090328216552734\n",
      "1499 14.566781997680664\n",
      "1599 12.816535949707031\n",
      "1699 11.601478576660156\n",
      "1799 10.757162094116211\n",
      "1899 10.169955253601074\n",
      "1999 9.761205673217773\n",
      "Result: y = 0.02908501587808132 + 0.8433764576911926 x + -0.005017649382352829 x^2 + -0.09142943471670151 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# Randomly initialize weights\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y\n",
    "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum().item()\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss)\n",
    "\n",
    "# Backprop to compute gradients of a, b, c, d with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_a = grad_y_pred.sum()\n",
    "    grad_b = (grad_y_pred * x).sum()\n",
    "    grad_c = (grad_y_pred * x ** 2).sum()\n",
    "    grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    a -= learning_rate * grad_a\n",
    "    b -= learning_rate * grad_b\n",
    "    c -= learning_rate * grad_c\n",
    "    d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b865e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Volumes/SamDick/Grad Project/Data/ANH4/'\n",
    "ndv = 3.4028230607371e+38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88ad24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = gdal.Open(file_path + 'R5_30GN1.TIF', gdal.GA_ReadOnly)\n",
    "# print(data_r.RasterCount)  1\n",
    "band_r = data_r.GetRasterBand(1)\n",
    "band_r.SetNoDataValue(ndv)\n",
    "# no data value -> 3.4028235e+38\n",
    "ele_r = band_r.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7bf27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = gdal.Open(file_path + 'M5_30GN1.TIF', gdal.GA_ReadOnly)\n",
    "# print(data_r.RasterCount)  1\n",
    "band_m = data_m.GetRasterBand(1)\n",
    "band_m.SetNoDataValue(ndv)\n",
    "# no data value -> 3.4028235e+38\n",
    "ele_m = band_m.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c5fa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4028235e+38, 3.4028235e+38, 3.4028235e+38, ..., 1.1067260e+01,\n",
       "        1.0528842e+01, 9.7950745e+00],\n",
       "       [3.4028235e+38, 3.4028235e+38, 3.4028235e+38, ..., 1.0511560e+01,\n",
       "        9.7509756e+00, 9.2790194e+00],\n",
       "       [3.4028235e+38, 3.4028235e+38, 3.4028235e+38, ..., 9.6854563e+00,\n",
       "        9.2926826e+00, 9.3123627e+00],\n",
       "       ...,\n",
       "       [2.0991859e+00, 2.4844029e+00, 3.4905410e+00, ..., 2.0533800e-01,\n",
       "        1.7054400e-01, 2.0660500e-01],\n",
       "       [2.7304480e+00, 3.7161262e+00, 4.8983092e+00, ..., 1.8084900e-01,\n",
       "        1.9876900e-01, 1.4985800e-01],\n",
       "       [4.1302629e+00, 5.2878218e+00, 5.7337070e+00, ..., 2.2286700e-01,\n",
       "        1.1971900e-01, 1.1189200e-01]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ele_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdf1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_r = np.ma.masked_where(ele_r > 10000, ele_r)\n",
    "masked_m = np.ma.masked_where(ele_m > 10000, ele_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "965e5aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[--, --, --, ..., 11.236674308776855, 10.71141529083252,\n",
       "         9.851737022399902],\n",
       "        [--, --, --, ..., 10.525714874267578, 9.752251625061035,\n",
       "         9.279019355773926],\n",
       "        [--, --, --, ..., 9.685456275939941, 9.292682647705078,\n",
       "         9.31330394744873],\n",
       "        ...,\n",
       "        [4.363124847412109, 7.6907830238342285, 12.57359504699707, ...,\n",
       "         0.5724790096282959, 0.6216700077056885, 1.774999976158142],\n",
       "        [5.719004154205322, 7.099827766418457, 16.24476432800293, ...,\n",
       "         1.1711349487304688, 0.6391350030899048, 0.9425870180130005],\n",
       "        [7.22181510925293, 12.524460792541504, 18.087730407714844, ...,\n",
       "         1.1704609394073486, 0.505062997341156, 0.12686499953269958]],\n",
       "  mask=[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]],\n",
       "  fill_value=1e+20,\n",
       "  dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c69a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 10)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d188142",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_ele_m = np.pad(ele_m, 2, pad_with, padder=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9714b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pad_m = np.ma.masked_where(padded_ele_m > 10000, padded_ele_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7c9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.arange(0, padded_ele_m.shape[1])\n",
    "y_ = np.arange(0, padded_ele_m.shape[0])\n",
    "\n",
    "xx, yy = np.meshgrid(x_, y_)\n",
    "#get only the valid values\n",
    "x1 = xx[~masked_pad_m.mask]\n",
    "y1 = yy[~masked_pad_m.mask]\n",
    "newarr = masked_pad_m[~masked_pad_m.mask]\n",
    "\n",
    "GD_m = interpolate.griddata((x1, y1), newarr.ravel(), (xx, yy), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2583ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_ele_r = np.pad(ele_r, 2, pad_with, padder=100000)\n",
    "masked_pad_r = np.ma.masked_where(padded_ele_r > 10000, padded_ele_r)\n",
    "\n",
    "x_ = np.arange(0, padded_ele_r.shape[1])\n",
    "y_ = np.arange(0, padded_ele_r.shape[0])\n",
    "\n",
    "xx, yy = np.meshgrid(x_, y_)\n",
    "#get only the valid values\n",
    "x1 = xx[~masked_pad_r.mask]\n",
    "y1 = yy[~masked_pad_r.mask]\n",
    "newarr = masked_pad_r[~masked_pad_r.mask]\n",
    "\n",
    "GD_r = interpolate.griddata((x1, y1), newarr.ravel(), (xx, yy), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f6322d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2550894, 1.2550894, 1.2550894, ..., 9.795074 , 9.795074 ,\n",
       "        9.795074 ],\n",
       "       [1.2550894, 1.2550894, 1.2550894, ..., 9.795074 , 9.795074 ,\n",
       "        9.795074 ],\n",
       "       [1.2402725, 1.2402725, 1.2550894, ..., 9.795074 , 9.795074 ,\n",
       "        9.795074 ],\n",
       "       ...,\n",
       "       [4.130263 , 4.130263 , 4.130263 , ..., 0.111892 , 0.111892 ,\n",
       "        0.111892 ],\n",
       "       [4.130263 , 4.130263 , 4.130263 , ..., 0.111892 , 0.111892 ,\n",
       "        0.111892 ],\n",
       "       [4.130263 , 4.130263 , 4.130263 , ..., 0.111892 , 0.111892 ,\n",
       "        0.111892 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GD_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea2a30e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_m_list = []\n",
    "# data_ele_list = []\n",
    "index_list = []\n",
    "label_list = []\n",
    "# tree_height = []\n",
    "for i in range(ele_r.shape[0]):\n",
    "    for j in range(ele_r.shape[1]):\n",
    "        if masked_r.mask[i][j] == False:\n",
    "#             pixel = [GD1[i+1][j+1], GD1[i+1][j+2], GD1[i+1][j+3], GD1[i+2][j+1], GD1[i+2][j+2], GD1[i+2][j+3], GD1[i+3][j+1], GD1[i+3][j+2], GD1[i+3][j+3]]\n",
    "#             data_list.append(pixel)\n",
    "            index_list.append((i, j))\n",
    "            if masked_m.mask[i][j] == False:\n",
    "                if masked_r.data[i][j]-masked_m.data[i][j]>2.0:\n",
    "                    label_list.append(int(1))\n",
    "                else:\n",
    "                    label_list.append(int(0))\n",
    "            else:\n",
    "                label_list.append(int(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71f9a186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428944  /  1080624\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in label_list:\n",
    "    if i == 1:\n",
    "        count += 1\n",
    "print(count, \" / \", len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7e92a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use train_test_split twice to split train / val / test\n",
    "\n",
    "index_train, index_test, label_train, label_test = train_test_split(index_list, label_list, test_size=0.2)\n",
    "index_train, index_val, label_train, label_val = train_test_split(index_train, label_train, test_size=0.25)\n",
    "\n",
    "# mean_train = np.mean(np.array(data_train))\n",
    "# std_train = np.std(np.array(data_train))\n",
    "# mean_test = np.mean(np.array(data_test))\n",
    "# std_test = np.std(np.array(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62f3a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m_train = []\n",
    "data_m_test = []\n",
    "data_m_val = []\n",
    "\n",
    "data_ele_train = []\n",
    "data_ele_test = []\n",
    "data_ele_val = []\n",
    "\n",
    "for it in index_train:\n",
    "    data_m_train.append(GD_m[it[0]+2][it[1]+2])\n",
    "    if masked_m.mask[i][j] == False:\n",
    "        data_ele_train.append(masked_r.data[it[0]][it[1]]-masked_m.data[it[0]][it[1]])\n",
    "    else:\n",
    "        data_ele_train.append(np.nan)\n",
    "\n",
    "for it in index_test:\n",
    "    data_m_test.append(GD_m[it[0]+2][it[1]+2])\n",
    "    if masked_m.mask[i][j] == False:\n",
    "        data_ele_test.append(masked_r.data[it[0]][it[1]]-masked_m.data[it[0]][it[1]])\n",
    "    else:\n",
    "        data_ele_test.append(np.nan)\n",
    "\n",
    "for it in index_val:\n",
    "    data_m_val.append(GD_m[it[0]+2][it[1]+2])\n",
    "    if masked_m.mask[i][j] == False:\n",
    "        data_ele_val.append(masked_r.data[it[0]][it[1]]-masked_m.data[it[0]][it[1]])\n",
    "    else:\n",
    "        data_ele_val.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ffd4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_m_train = np.mean(np.array(data_m_train), dtype=np.float64)\n",
    "std_m_train = np.std(np.array(data_m_train), dtype=np.float64)\n",
    "mean_ele_train = np.mean(np.array(data_ele_train), dtype=np.float64)\n",
    "std_ele_train = np.std(np.array(data_ele_train), dtype=np.float64)\n",
    "mean_m_test = np.mean(np.array(data_m_test), dtype=np.float64)\n",
    "std_m_test = np.std(np.array(data_m_test), dtype=np.float64)\n",
    "mean_ele_test = np.mean(np.array(data_ele_test), dtype=np.float64)\n",
    "std_ele_test = np.std(np.array(data_ele_test), dtype=np.float64)\n",
    "mean_m_val = np.mean(np.array(data_m_val), dtype=np.float64)\n",
    "std_m_val = np.std(np.array(data_m_val), dtype=np.float64)\n",
    "mean_ele_val = np.mean(np.array(data_ele_val), dtype=np.float64)\n",
    "std_ele_val = np.std(np.array(data_ele_val), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8262ed1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.287058628360828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.169393945443095"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-2.7438857275207777e+37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9.26502447601632e+37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.271529781062127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.162737729876422"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-2.7553226448463877e+37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9.282616153663652e+37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.284413252685591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5.161313305796146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-2.7172204688433687e+37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "9.223823972243028e+37"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(mean_m_train, std_m_train, mean_ele_train, std_ele_train, mean_m_test, std_m_test, mean_ele_test, std_ele_test, mean_m_val, std_m_val, mean_ele_val, std_ele_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b0e41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[mean_train],\n",
    "        std=[std_train],\n",
    "    ),\n",
    "])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[mean_test],\n",
    "        std=[std_test],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# output[channel] = (input[channel] - mean[channel]) / std[channel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7935e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ML_path = '/Volumes/SamDick/Grad Project/Data/ML/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11e6aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(value, mean, std):\n",
    "    return (value - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0bfa5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "dict_dl = {'file_name':[], 'label':[]}\n",
    "for i in range(3000):\n",
    "    file_name_ = data_ML_path+'train/'+str(count)+'.npy'\n",
    "    list_temp = []\n",
    "    for i_ in range(1, 4):\n",
    "        for j_ in range(1, 4):\n",
    "            normalized_value = normalize(GD_m[index_train[i][0]+i_][index_train[i][1]+j_], mean_m_train, std_m_train) +\\\n",
    "            normalize(GD_r[index_train[i][0]+i_][index_train[i][1]+j_] - GD_m[index_train[i][0]+i_][index_train[i][1]+j_], mean_ele_train, std_ele_train)\n",
    "            \n",
    "            list_temp.append(normalized_value)\n",
    "    np.save(file_name_, np.array(list_temp).reshape(3,3))\n",
    "    dict_dl['file_name'].append(str(count)+'.npy')\n",
    "    dict_dl['label'].append(label_train[i])\n",
    "    count = count+1\n",
    "\n",
    "for j in range(1000):\n",
    "    file_name_ = data_ML_path+'test/'+str(count)+'.npy'\n",
    "    list_temp = []\n",
    "    for i_ in range(1, 4):\n",
    "        for j_ in range(1, 4):\n",
    "            normalized_value = normalize(GD_m[index_test[j][0]+i_][index_test[j][1]+j_], mean_m_test, std_m_test) +\\\n",
    "            normalize(GD_r[index_test[j][0]+i_][index_test[j][1]+j_] - GD_m[index_test[j][0]+i_][index_test[j][1]+j_], mean_ele_test, std_ele_test)\n",
    "            \n",
    "            list_temp.append(normalized_value)\n",
    "    np.save(file_name_, np.array(list_temp).reshape(3,3))\n",
    "    dict_dl['file_name'].append(str(count)+'.npy')\n",
    "    dict_dl['label'].append(label_test[j])\n",
    "    count = count+1\n",
    "    \n",
    "for k in range(1000):\n",
    "    file_name_ = data_ML_path+'val/'+str(count)+'.npy'\n",
    "    list_temp = []\n",
    "    for i_ in range(1, 4):\n",
    "        for j_ in range(1, 4):\n",
    "            normalized_value = normalize(GD_m[index_val[k][0]+i_][index_val[k][1]+j_], mean_m_val, std_m_val) +\\\n",
    "            normalize(GD_r[index_val[k][0]+i_][index_val[k][1]+j_] - GD_m[index_val[k][0]+i_][index_val[k][1]+j_], mean_ele_val, std_ele_val)\n",
    "            \n",
    "            list_temp.append(normalized_value)\n",
    "    np.save(file_name_, np.array(list_temp).reshape(3,3))\n",
    "    dict_dl['file_name'].append(str(count)+'.npy')\n",
    "    dict_dl['label'].append(label_test[j])\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e8b3c9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34990677, 0.43514149, 0.50346652],\n",
       "       [0.29272361, 0.40154082, 0.53656014],\n",
       "       [0.32406323, 0.33970311, 0.47502405]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(data_ML_path+'train/'+'0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8fd0249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999.npy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  label\n",
       "0        0.npy      0\n",
       "1        1.npy      0\n",
       "2        2.npy      0\n",
       "3        3.npy      0\n",
       "4        4.npy      0\n",
       "...        ...    ...\n",
       "4995  4995.npy      0\n",
       "4996  4996.npy      0\n",
       "4997  4997.npy      0\n",
       "4998  4998.npy      0\n",
       "4999  4999.npy      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(dict_dl)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "58b9b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_ML_path+'labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3add72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyData(Dataset):\n",
    "    def __init__(self, setname):\n",
    "        \"\"\"\n",
    "        Variables:\n",
    "       <setname> can be any of: 'train' to specify the training set\n",
    "                                'test' to specify the test set\"\"\"\n",
    "        self.setname = setname\n",
    "        assert setname in ['train','test']\n",
    "        \n",
    "        #Define dataset\n",
    "        overall_dataset_dir = '/Volumes/SamDick/Grad Project/Data/ML'\n",
    "        self.selected_dataset_dir = os.path.join(overall_dataset_dir,setname)\n",
    "        \n",
    "        #E.g. self.all_filenames = ['006.png','007.png','008.png'] when setname=='val'\n",
    "        self.all_filenames = os.listdir(self.selected_dataset_dir)\n",
    "        self.all_labels = pd.read_csv(os.path.join(overall_dataset_dir,'labels.csv'),header=0,index_col=0)\n",
    "        self.label_meanings = self.all_labels.columns.values.tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of examples in this split, e.g. if\n",
    "        self.setname=='train' then return the total number of examples\n",
    "        in the training set\"\"\"\n",
    "        return len(self.all_filenames)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Return the example at index [idx]. The example is a dict with keys\n",
    "        'data' (value: Tensor for an RGB image) and 'label' (value: multi-hot\n",
    "        vector as Torch tensor of gr truth class labels).\"\"\"\n",
    "        selected_filename = self.all_filenames[idx]\n",
    "#         imagepil = PIL.Image.open(os.path.join(self.selected_dataset_dir,selected_filename)).convert('RGB')\n",
    "        \n",
    "#         #convert image to Tensor and normalize\n",
    "#         image = utils.to_tensor_and_normalize(imagepil)\n",
    "        \n",
    "        npy = np.load(os.path.join(self.selected_dataset_dir,selected_filename))\n",
    "        pimg = torch.from_numpy(npy)\n",
    "        \n",
    "        #load label\n",
    "        label = torch.Tensor(self.all_labels.loc[selected_filename,:].values)\n",
    "        \n",
    "        sample = {'data':pimg, #preprocessed image, for input into NN\n",
    "                  'label':label,\n",
    "                  'img_idx':idx}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9904cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TinyData(setname = 'train')\n",
    "test_dataset = TinyData(setname = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2aedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c77ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = train_dataset[0]\n",
    "simple['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f419ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbf9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e3d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(file_path+'test.npy', transform_train(np.array(data_train[5000]).reshape(3,3)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386a9797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = np.array(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9276e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.arange(10).reshape((5, 2)), range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b454f697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b724bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from affine import Affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0c53016",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_crs='EPSG:28992'\n",
    "out_file = file_path + 'M5_30GN1_ip.TIF'\n",
    "afn = Affine.from_gdal(*data_r.GetGeoTransform())\n",
    "with rasterio.open(\n",
    "    out_file,\n",
    "    'w',\n",
    "    driver='GTiff',\n",
    "    height=padded_ele_r.shape[0],\n",
    "    width=padded_ele_r.shape[1],\n",
    "    count=1,\n",
    "    dtype=np.float32,\n",
    "    crs=data_m.GetProjection(),\n",
    "    transform=afn,\n",
    ") as dest_file:\n",
    "    dest_file.write(GD_m, 1)\n",
    "dest_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b9933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000.0, 5.0, 0.0, 462500.0, 0.0, -5.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_m.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4521adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "out_file = file_path + 'M5_30GN1_ip.TIF'\n",
    "\n",
    "outdata = driver.Create(out_file, padded_ele_m.shape[1],  padded_ele_m.shape[0], 1, gdal.GDT_UInt16)\n",
    "outdata.SetGeoTransform(data_m.GetGeoTransform())##sets same geotransform as input\n",
    "outdata.SetProjection(data_m.GetProjection())##sets same projection as input\n",
    "outdata.GetRasterBand(1).WriteArray(GD_m)\n",
    "# outdata.GetRasterBand(1).SetNoDataValue(10000)##if you want these values transparent\n",
    "outdata.FlushCache() ##saves to disk!!\n",
    "outdata = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8af92737554b8d7e77b438513b3bb470b0fcb31762f2300d530491e7c048b893"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
